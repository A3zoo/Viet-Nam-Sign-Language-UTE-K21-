{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class ConvTemporalGraphical(nn.Module):\n",
    "    \"\"\"The basic module for applying a graph convolution.\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input sequence data.\n",
    "        out_channels (int): Number of channels produced by the convolution.\n",
    "        kernel_size (int): Size of the graph convolving kernel.\n",
    "        t_kernel_size (int): Size of the temporal convolving kernel.\n",
    "        t_stride (int, optional): Stride of the temporal convolution. Default: 1.\n",
    "        t_padding (int, optional): Temporal zero-padding added to both sides\n",
    "            of the input. Default: 0.\n",
    "        t_dilation (int, optional): Spacing between temporal kernel elements.\n",
    "            Default: 1.\n",
    "        bias (bool, optional): If ``True``, adds a learnable bias to the\n",
    "            output. Default: ``True``.\n",
    "    Shape:\n",
    "        - Input[0]: Input graph sequence in :math:`(N, in_channels, T_{in}, V)`\n",
    "            format\n",
    "        - Input[1]: Input graph adjacency matrix in :math:`(K, V, V)` format\n",
    "        - Output[0]: Output graph sequence in :math:`(N, out_channels, T_{out}\n",
    "            , V)` format\n",
    "        - Output[1]: Graph adjacency matrix for output data in :math:`(K, V, V)\n",
    "            ` format\n",
    "        where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]\n",
    "                `,\n",
    "            :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "            :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        t_kernel_size=1,\n",
    "        t_stride=1,\n",
    "        t_padding=0,\n",
    "        t_dilation=1,\n",
    "        bias=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels * kernel_size,\n",
    "            kernel_size=(t_kernel_size, 1),\n",
    "            padding=(t_padding, 0),\n",
    "            stride=(t_stride, 1),\n",
    "            dilation=(t_dilation, 1),\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        assert A.size(0) == self.kernel_size\n",
    "\n",
    "        x = self.conv(x)\n",
    "        n, kc, t, v = x.size()\n",
    "        x = x.view(n, self.kernel_size, kc // self.kernel_size, t, v)\n",
    "        x = torch.einsum(\"nkctv,kvw->nctw\", (x, A))\n",
    "\n",
    "        return x.contiguous(), A                                                                                \n",
    "\n",
    "\n",
    "class STGCN_BLOCK(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies a spatial temporal graph convolution over an input graph\n",
    "    sequence.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input sequence data.\n",
    "        out_channels (int): Number of channels produced by the convolution.\n",
    "        kernel_size (tuple): Size of the temporal convolving kernel and\n",
    "            graph convolving kernel.\n",
    "        stride (int, optional): Stride of the temporal convolution. Default: 1.\n",
    "        dropout (int, optional): Dropout rate of the final output. Default: 0.\n",
    "        residual (bool, optional): If ``True``, applies a residual mechanism. Default: ``True``.\n",
    "    Shape:\n",
    "        - Input[0]: Input graph sequence in :math:`(N, in_channels, T_{in}, V)`\n",
    "            format.\n",
    "        - Input[1]: Input graph adjacency matrix in :math:`(K, V, V)` format\n",
    "        - Output[0]: Output graph sequence in :math:`(N, out_channels, T_{out},\n",
    "            V)` format.\n",
    "        - Output[1]: Graph adjacency matrix for output data in :math:`(K, V,\n",
    "            V)` format.\n",
    "        where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "            :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "            :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size, stride=1, dropout=0, residual=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "\n",
    "        self.gcn = ConvTemporalGraphical(in_channels, out_channels, kernel_size[1])\n",
    "\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                (kernel_size[0], 1),\n",
    "                (stride, 1),\n",
    "                padding,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(dropout, inplace=True),\n",
    "        )\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "\n",
    "        else:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=(stride, 1)),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        res = self.residual(x)\n",
    "        x, A = self.gcn(x, A)\n",
    "        x = self.tcn(x) + res\n",
    "\n",
    "        return self.relu(x), A\n",
    "\n",
    "class FC(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully connected layer head\n",
    "    Args:\n",
    "        n_features (int): Number of features in the input.\n",
    "        num_class (int): Number of class for classification.\n",
    "        dropout_ratio (float): Dropout ratio to use. Default: 0.2.\n",
    "        batch_norm (bool): Whether to use batch norm or not. Default: ``False``.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, num_class, dropout_ratio=0.2, batch_norm=False):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout_ratio)\n",
    "        self.bn = batch_norm\n",
    "        self.n_features = n_features\n",
    "        if batch_norm:\n",
    "            self.bn = nn.BatchNorm1d(self.n_features)\n",
    "            self.bn.weight.data.fill_(1)\n",
    "            self.bn.bias.data.zero_()\n",
    "        self.classifier = nn.Linear(n_features, num_class)\n",
    "        nn.init.normal_(self.classifier.weight, 0, math.sqrt(2.0 / num_class))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape: (batch_size, n_features)\n",
    "        \n",
    "        returns:\n",
    "            torch.Tensor: logits for classification.\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        if self.bn:\n",
    "            x = self.bn(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"Spatial temporal graph convolutional network backbone\n",
    "    \n",
    "    This module is proposed in\n",
    "    `Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\n",
    "    <https://arxiv.org/pdf/1801.07455.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input data.\n",
    "        graph_args (dict): The arguments for building the graph.\n",
    "        edge_importance_weighting (bool): If ``True``, adds a learnable importance weighting to the edges of the graph. Default: True.\n",
    "        n_out_features (int): Output Embedding dimension. Default: 256. \n",
    "        kwargs (dict): Other parameters for graph convolution units.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels = 2,\n",
    "                 num_nodes = 29,\n",
    "                 center = 0,\n",
    "                 inward_edges = None,\n",
    "                 edge_importance_weighting = True,\n",
    "                 n_out_features = 256,\n",
    "                 n_classes = 1000,\n",
    "                 dropout_ratio = 0.05,\n",
    "                 batch_norm=False,) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.graph = GraphWithPartition(num_nodes, center, inward_edges)\n",
    "        A = torch.tensor(self.graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer(\"A\", A)\n",
    "\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        self.n_out_features = n_out_features\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        self.st_gcn_networks = nn.ModuleList(\n",
    "            (\n",
    "                STGCN_BLOCK(in_channels, 64, kernel_size, 1, residual=False,),\n",
    "                STGCN_BLOCK(64, 64, kernel_size, 1,),\n",
    "                STGCN_BLOCK(64, 64, kernel_size, 1,),\n",
    "                STGCN_BLOCK(64, 64, kernel_size, 1,),\n",
    "                STGCN_BLOCK(64, 128, kernel_size, 2,),\n",
    "                STGCN_BLOCK(128, 128, kernel_size, 1,),\n",
    "                STGCN_BLOCK(128, 128, kernel_size, 1,),\n",
    "                STGCN_BLOCK(128, 256, kernel_size, 2,),\n",
    "                STGCN_BLOCK(256, 256, kernel_size, 1,),\n",
    "                STGCN_BLOCK(256, self.n_out_features, kernel_size, 1,),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if edge_importance_weighting:\n",
    "            self.edge_importance = nn.ParameterList(\n",
    "                [nn.Parameter(torch.ones(self.A.size())) for i in self.st_gcn_networks]\n",
    "            )\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "        \n",
    "        self.head = FC(self.n_out_features, n_classes, dropout_ratio, batch_norm)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            x (torch.Tensor): Input tensor of shape :math:`(N, in\\_channels, T_{in}, V_{in})`\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Output embedding of shape :math:`(N, n\\_out\\_features)`\n",
    "\n",
    "        where\n",
    "            - :math:`N` is a batch size,\n",
    "            - :math:`T_{in}` is a length of input sequence,\n",
    "            - :math:`V_{in}` is the number of graph nodes,\n",
    "            - :math:`n\\_out\\_features` is the output embedding dimension.\n",
    "\n",
    "            our input is in shape ntvc\n",
    "        \"\"\"\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous() # NCTV -> NVCT\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous() # NVCT -> NCTV\n",
    "\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x, _ = gcn(x, self.A * importance)\n",
    "\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = x.view(N, -1)\n",
    "\n",
    "        return self.head(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class ConvTemporalGraphical(nn.Module):\n",
    "    \"\"\"The basic module for applying a graph convolution.\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input sequence data.\n",
    "        out_channels (int): Number of channels produced by the convolution.\n",
    "        kernel_size (int): Size of the graph convolving kernel.\n",
    "        t_kernel_size (int): Size of the temporal convolving kernel.\n",
    "        t_stride (int, optional): Stride of the temporal convolution. Default: 1.\n",
    "        t_padding (int, optional): Temporal zero-padding added to both sides\n",
    "            of the input. Default: 0.\n",
    "        t_dilation (int, optional): Spacing between temporal kernel elements.\n",
    "            Default: 1.\n",
    "        bias (bool, optional): If ``True``, adds a learnable bias to the\n",
    "            output. Default: ``True``.\n",
    "    Shape:\n",
    "        - Input[0]: Input graph sequence in :math:`(N, in_channels, T_{in}, V)`\n",
    "            format\n",
    "        - Input[1]: Input graph adjacency matrix in :math:`(K, V, V)` format\n",
    "        - Output[0]: Output graph sequence in :math:`(N, out_channels, T_{out}\n",
    "            , V)` format\n",
    "        - Output[1]: Graph adjacency matrix for output data in :math:`(K, V, V)\n",
    "            ` format\n",
    "        where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]\n",
    "                `,\n",
    "            :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "            :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        t_kernel_size=1,\n",
    "        t_stride=1,\n",
    "        t_padding=0,\n",
    "        t_dilation=1,\n",
    "        bias=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels * kernel_size,\n",
    "            kernel_size=(t_kernel_size, 1),\n",
    "            padding=(t_padding, 0),\n",
    "            stride=(t_stride, 1),\n",
    "            dilation=(t_dilation, 1),\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        assert A.size(0) == self.kernel_size\n",
    "\n",
    "        x = self.conv(x)\n",
    "        n, kc, t, v = x.size()\n",
    "        x = x.view(n, self.kernel_size, kc // self.kernel_size, t, v)\n",
    "        x = torch.einsum(\"nkctv,kvw->nctw\", (x, A))\n",
    "\n",
    "        return x.contiguous(), A                                                                                \n",
    "\n",
    "\n",
    "class STGCN_BLOCK(nn.Module):\n",
    "    \"\"\"\n",
    "    Applies a spatial temporal graph convolution over an input graph\n",
    "    sequence.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input sequence data.\n",
    "        out_channels (int): Number of channels produced by the convolution.\n",
    "        kernel_size (tuple): Size of the temporal convolving kernel and\n",
    "            graph convolving kernel.\n",
    "        stride (int, optional): Stride of the temporal convolution. Default: 1.\n",
    "        dropout (int, optional): Dropout rate of the final output. Default: 0.\n",
    "        residual (bool, optional): If ``True``, applies a residual mechanism. Default: ``True``.\n",
    "    Shape:\n",
    "        - Input[0]: Input graph sequence in :math:`(N, in_channels, T_{in}, V)`\n",
    "            format.\n",
    "        - Input[1]: Input graph adjacency matrix in :math:`(K, V, V)` format\n",
    "        - Output[0]: Output graph sequence in :math:`(N, out_channels, T_{out},\n",
    "            V)` format.\n",
    "        - Output[1]: Graph adjacency matrix for output data in :math:`(K, V,\n",
    "            V)` format.\n",
    "        where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "            :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "            :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size, stride=1, dropout=0, residual=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "\n",
    "        self.gcn = ConvTemporalGraphical(in_channels, out_channels, kernel_size[1])\n",
    "\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                (kernel_size[0], 1),\n",
    "                (stride, 1),\n",
    "                padding,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(dropout, inplace=True),\n",
    "        )\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "\n",
    "        else:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=(stride, 1)),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        res = self.residual(x)\n",
    "        x, A = self.gcn(x, A)\n",
    "        x = self.tcn(x) + res\n",
    "\n",
    "        return self.relu(x), A\n",
    "\n",
    "class FC(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully connected layer head\n",
    "    Args:\n",
    "        n_features (int): Number of features in the input.\n",
    "        num_class (int): Number of class for classification.\n",
    "        dropout_ratio (float): Dropout ratio to use. Default: 0.2.\n",
    "        batch_norm (bool): Whether to use batch norm or not. Default: ``False``.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, num_class, dropout_ratio=0.2, batch_norm=False):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout_ratio)\n",
    "        self.bn = batch_norm\n",
    "        self.n_features = n_features\n",
    "        if batch_norm:\n",
    "            self.bn = nn.BatchNorm1d(self.n_features)\n",
    "            self.bn.weight.data.fill_(1)\n",
    "            self.bn.bias.data.zero_()\n",
    "        self.classifier = nn.Linear(n_features, num_class)\n",
    "        nn.init.normal_(self.classifier.weight, 0, math.sqrt(2.0 / num_class))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape: (batch_size, n_features)\n",
    "        \n",
    "        returns:\n",
    "            torch.Tensor: logits for classification.\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        if self.bn:\n",
    "            x = self.bn(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"Spatial temporal graph convolutional network backbone\n",
    "    \n",
    "    This module is proposed in\n",
    "    `Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\n",
    "    <https://arxiv.org/pdf/1801.07455.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input data.\n",
    "        graph_args (dict): The arguments for building the graph.\n",
    "        edge_importance_weighting (bool): If ``True``, adds a learnable importance weighting to the edges of the graph. Default: True.\n",
    "        n_out_features (int): Output Embedding dimension. Default: 256. \n",
    "        kwargs (dict): Other parameters for graph convolution units.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_channels = 2,\n",
    "                 num_nodes = 29,\n",
    "                 center = 0,\n",
    "                 inward_edges = None,\n",
    "                 edge_importance_weighting = True,\n",
    "                 n_out_features = 256,\n",
    "                 n_classes = 1000,\n",
    "                 dropout_ratio = 0.05,\n",
    "                 batch_norm=False,) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.graph = GraphWithPartition(num_nodes, center, inward_edges)\n",
    "        A = torch.tensor(self.graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer(\"A\", A)\n",
    "\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        self.n_out_features = n_out_features\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        self.st_gcn_networks = nn.ModuleList(\n",
    "            (\n",
    "                STGCN_BLOCK(in_channels, 64, kernel_size, 1, residual=False,),\n",
    "                STGCN_BLOCK(64, 64, kernel_size, 1,),\n",
    "                STGCN_BLOCK(64, 64, kernel_size, 1,),\n",
    "                STGCN_BLOCK(64, 64, kernel_size, 1,),\n",
    "                STGCN_BLOCK(64, 128, kernel_size, 2,),\n",
    "                STGCN_BLOCK(128, 128, kernel_size, 1,),\n",
    "                STGCN_BLOCK(128, 128, kernel_size, 1,),\n",
    "                STGCN_BLOCK(128, 256, kernel_size, 2,),\n",
    "                STGCN_BLOCK(256, 256, kernel_size, 1,),\n",
    "                STGCN_BLOCK(256, self.n_out_features, kernel_size, 1,),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if edge_importance_weighting:\n",
    "            self.edge_importance = nn.ParameterList(\n",
    "                [nn.Parameter(torch.ones(self.A.size())) for i in self.st_gcn_networks]\n",
    "            )\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "        \n",
    "        self.head = FC(self.n_out_features, n_classes, dropout_ratio, batch_norm)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            x (torch.Tensor): Input tensor of shape :math:`(N, in\\_channels, T_{in}, V_{in})`\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Output embedding of shape :math:`(N, n\\_out\\_features)`\n",
    "\n",
    "        where\n",
    "            - :math:`N` is a batch size,\n",
    "            - :math:`T_{in}` is a length of input sequence,\n",
    "            - :math:`V_{in}` is the number of graph nodes,\n",
    "            - :math:`n\\_out\\_features` is the output embedding dimension.\n",
    "\n",
    "            our input is in shape ntvc\n",
    "        \"\"\"\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous() # NCTV -> NVCT\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous() # NVCT -> NCTV\n",
    "\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x, _ = gcn(x, self.A * importance)\n",
    "\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = x.view(N, -1)\n",
    "\n",
    "        return self.head(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "parent_dir = 'D:\\\\Semester_7\\\\GraduationProject\\\\SLR\\\\data_set\\\\mediapipe_sequences'\n",
    "a =[]\n",
    "lable_decode = []\n",
    "for lable in os.listdir(parent_dir):\n",
    "    video_dir = os.path.join(parent_dir, lable)\n",
    "    for file_name in os.listdir(video_dir):\n",
    "        lable_decode.append(lable)\n",
    "        input_file = os.path.join(video_dir, file_name)\n",
    "        tensor = torch.load(input_file)\n",
    "        tensor = torch.einsum('xyz->zxy', tensor)\n",
    "        a.append(tensor)\n",
    "\n",
    "batch = torch.stack(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = batch[:, 0]\n",
    "batch_y = batch[:, 1]\n",
    "batch_vi = batch[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([501, 25, 67])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.shape\n",
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6382, 0.6610, 0.6770,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.6367, 0.6600, 0.6758,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.6332, 0.6577, 0.6724,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.6277, 0.6525, 0.6668,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.6279, 0.6528, 0.6671,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.6281, 0.6529, 0.6672,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.5045, 0.5155, 0.5245,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.5020, 0.5125, 0.5221,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4952, 0.5067, 0.5148,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.5092, 0.5234, 0.5321,  ..., 0.6279, 0.6244, 0.6206],\n",
      "         [0.5081, 0.5226, 0.5312,  ..., 0.6284, 0.6255, 0.6229],\n",
      "         [0.5076, 0.5216, 0.5301,  ..., 0.6294, 0.6267, 0.6225]],\n",
      "\n",
      "        [[0.4818, 0.4946, 0.5027,  ..., 0.6083, 0.6032, 0.5977],\n",
      "         [0.4838, 0.4958, 0.5043,  ..., 0.6077, 0.6053, 0.6025],\n",
      "         [0.4853, 0.4973, 0.5068,  ..., 0.6132, 0.6088, 0.6042],\n",
      "         ...,\n",
      "         [0.5187, 0.5320, 0.5421,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.5208, 0.5324, 0.5426,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.5190, 0.5316, 0.5412,  ..., 0.6453, 0.6380, 0.6312]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5760, 0.5957, 0.6062,  ..., 0.6674, 0.6700, 0.6734],\n",
      "         [0.5754, 0.5947, 0.6053,  ..., 0.6748, 0.6666, 0.6622],\n",
      "         [0.5748, 0.5931, 0.6041,  ..., 0.6872, 0.6760, 0.6677],\n",
      "         ...,\n",
      "         [0.5778, 0.5972, 0.6089,  ..., 0.6634, 0.6477, 0.6326],\n",
      "         [0.5777, 0.5960, 0.6085,  ..., 0.6562, 0.6357, 0.6171],\n",
      "         [0.5774, 0.5942, 0.6077,  ..., 0.6690, 0.6523, 0.6364]],\n",
      "\n",
      "        [[0.5566, 0.5737, 0.5900,  ..., 0.6507, 0.6573, 0.6640],\n",
      "         [0.5561, 0.5727, 0.5894,  ..., 0.6499, 0.6560, 0.6650],\n",
      "         [0.5561, 0.5722, 0.5891,  ..., 0.6453, 0.6340, 0.6285],\n",
      "         ...,\n",
      "         [0.5679, 0.5856, 0.5981,  ..., 0.6366, 0.6189, 0.6014],\n",
      "         [0.5683, 0.5859, 0.5983,  ..., 0.6370, 0.6185, 0.6004],\n",
      "         [0.5686, 0.5861, 0.5985,  ..., 0.6413, 0.6237, 0.6064]],\n",
      "\n",
      "        [[0.5546, 0.5713, 0.5882,  ..., 0.6371, 0.6320, 0.6331],\n",
      "         [0.5539, 0.5699, 0.5870,  ..., 0.6570, 0.6435, 0.6337],\n",
      "         [0.5534, 0.5691, 0.5860,  ..., 0.6451, 0.6260, 0.6085],\n",
      "         ...,\n",
      "         [0.5639, 0.5786, 0.5953,  ..., 0.6514, 0.6373, 0.6240],\n",
      "         [0.5643, 0.5787, 0.5954,  ..., 0.6571, 0.6463, 0.6355],\n",
      "         [0.5644, 0.5787, 0.5953,  ..., 0.6514, 0.6375, 0.6236]]])\n",
      "tensor([[[0.4790, 0.4295, 0.4295,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4791, 0.4295, 0.4296,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4792, 0.4293, 0.4294,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.4882, 0.4263, 0.4276,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4881, 0.4262, 0.4274,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.4881, 0.4263, 0.4276,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2864, 0.2587, 0.2633,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2843, 0.2574, 0.2610,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2842, 0.2574, 0.2606,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.2871, 0.2573, 0.2578,  ..., 1.0079, 1.0202, 1.0289],\n",
      "         [0.2875, 0.2575, 0.2580,  ..., 1.0075, 1.0197, 1.0294],\n",
      "         [0.2882, 0.2581, 0.2586,  ..., 0.9979, 1.0101, 1.0195]],\n",
      "\n",
      "        [[0.2762, 0.2503, 0.2515,  ..., 1.0131, 1.0282, 1.0379],\n",
      "         [0.2753, 0.2503, 0.2515,  ..., 1.0061, 1.0204, 1.0308],\n",
      "         [0.2743, 0.2502, 0.2515,  ..., 1.0024, 1.0158, 1.0256],\n",
      "         ...,\n",
      "         [0.2918, 0.2630, 0.2637,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2907, 0.2622, 0.2631,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2906, 0.2615, 0.2623,  ..., 1.0177, 1.0299, 1.0367]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2575, 0.2207, 0.2239,  ..., 0.7182, 0.7316, 0.7304],\n",
      "         [0.2576, 0.2210, 0.2242,  ..., 0.6969, 0.7177, 0.7360],\n",
      "         [0.2594, 0.2221, 0.2251,  ..., 0.6098, 0.6242, 0.6370],\n",
      "         ...,\n",
      "         [0.2614, 0.2248, 0.2268,  ..., 0.5707, 0.5807, 0.5879],\n",
      "         [0.2620, 0.2255, 0.2273,  ..., 0.5580, 0.5650, 0.5687],\n",
      "         [0.2620, 0.2255, 0.2271,  ..., 0.5656, 0.5732, 0.5779]],\n",
      "\n",
      "        [[0.2653, 0.2256, 0.2258,  ..., 0.6884, 0.7049, 0.7074],\n",
      "         [0.2642, 0.2250, 0.2252,  ..., 0.6865, 0.7010, 0.7017],\n",
      "         [0.2642, 0.2248, 0.2248,  ..., 0.6432, 0.6595, 0.6735],\n",
      "         ...,\n",
      "         [0.2579, 0.2221, 0.2218,  ..., 0.5713, 0.5770, 0.5787],\n",
      "         [0.2575, 0.2221, 0.2218,  ..., 0.5716, 0.5771, 0.5785],\n",
      "         [0.2574, 0.2222, 0.2219,  ..., 0.5677, 0.5739, 0.5766]],\n",
      "\n",
      "        [[0.2659, 0.2265, 0.2263,  ..., 0.6188, 0.6369, 0.6508],\n",
      "         [0.2665, 0.2266, 0.2264,  ..., 0.6136, 0.6224, 0.6310],\n",
      "         [0.2668, 0.2267, 0.2264,  ..., 0.5860, 0.5881, 0.5900],\n",
      "         ...,\n",
      "         [0.2653, 0.2244, 0.2235,  ..., 0.5561, 0.5644, 0.5689],\n",
      "         [0.2653, 0.2244, 0.2234,  ..., 0.5589, 0.5644, 0.5661],\n",
      "         [0.2652, 0.2243, 0.2233,  ..., 0.5601, 0.5678, 0.5704]]])\n"
     ]
    }
   ],
   "source": [
    "print(batch_x)\n",
    "print(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_reshape = batch_x.reshape(501*25, 67)\n",
    "batch_y_reshape = batch_y.reshape(501*25, 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x_reshape = batch_x_reshape.t()\n",
    "batch_y_reshape = batch_y_reshape.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6382, 0.6367, 0.6332,  ..., 0.5639, 0.5643, 0.5644],\n",
      "        [0.6610, 0.6600, 0.6577,  ..., 0.5786, 0.5787, 0.5787],\n",
      "        [0.6770, 0.6758, 0.6724,  ..., 0.5953, 0.5954, 0.5953],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6514, 0.6571, 0.6514],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6373, 0.6463, 0.6375],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.6240, 0.6355, 0.6236]])\n",
      "tensor([[0.4790, 0.4791, 0.4792,  ..., 0.2653, 0.2653, 0.2652],\n",
      "        [0.4295, 0.4295, 0.4293,  ..., 0.2244, 0.2244, 0.2243],\n",
      "        [0.4295, 0.4296, 0.4294,  ..., 0.2235, 0.2234, 0.2233],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.5561, 0.5589, 0.5601],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.5644, 0.5644, 0.5678],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.5689, 0.5661, 0.5704]])\n"
     ]
    }
   ],
   "source": [
    "print(batch_x_reshape)\n",
    "print(batch_y_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67, 12525])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x_reshape.shape\n",
    "batch_y_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([67, 12525])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo đối tượng StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_scaled_data = scaler.fit_transform(batch_x_reshape.numpy())\n",
    "y_scaled_data = scaler.fit_transform(batch_y_reshape.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = torch.from_numpy(x_scaled_data).t()\n",
    "batch_y = torch.from_numpy(y_scaled_data).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = batch_x.reshape(-1, 25, 67)\n",
    "batch_y = batch_y.reshape(-1, 25, 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_xy = torch.stack([batch_x, batch_y], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([501, 2, 25, 67])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000,  0.0764,  0.1298,  ..., -2.1361, -2.1361, -2.1361],\n",
       "          [ 0.0000,  0.0784,  0.1315,  ..., -2.1408, -2.1408, -2.1408],\n",
       "          [ 0.0000,  0.0824,  0.1324,  ..., -2.1377, -2.1377, -2.1377],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0821,  0.1295,  ..., -2.0772, -2.0772, -2.0772],\n",
       "          [ 0.0000,  0.0829,  0.1306,  ..., -2.0912, -2.0912, -2.0912],\n",
       "          [ 0.0000,  0.0826,  0.1301,  ..., -2.0887, -2.0887, -2.0887]],\n",
       "\n",
       "         [[ 0.0000, -0.1042, -0.1042,  ..., -1.0096, -1.0096, -1.0096],\n",
       "          [ 0.0000, -0.1055, -0.1054,  ..., -1.0186, -1.0186, -1.0186],\n",
       "          [ 0.0000, -0.1071, -0.1069,  ..., -1.0301, -1.0301, -1.0301],\n",
       "          ...,\n",
       "          [ 0.0000, -0.1398, -0.1368,  ..., -1.1023, -1.1023, -1.1023],\n",
       "          [ 0.0000, -0.1401, -0.1372,  ..., -1.1034, -1.1034, -1.1034],\n",
       "          [ 0.0000, -0.1410, -0.1380,  ..., -1.1140, -1.1140, -1.1140]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0493,  0.0897,  ..., -2.2736, -2.2736, -2.2736],\n",
       "          [ 0.0000,  0.0471,  0.0898,  ..., -2.2457, -2.2457, -2.2457],\n",
       "          [ 0.0000,  0.0507,  0.0866,  ..., -2.1957, -2.1957, -2.1957],\n",
       "          ...,\n",
       "          [ 0.0000,  0.1761,  0.2847,  ...,  1.4715,  1.4286,  1.3816],\n",
       "          [ 0.0000,  0.1859,  0.2962,  ...,  1.5437,  1.5071,  1.4733],\n",
       "          [ 0.0000,  0.1831,  0.2936,  ...,  1.5858,  1.5509,  1.4961]],\n",
       "\n",
       "         [[ 0.0000, -0.0713, -0.0594,  ..., -0.7370, -0.7370, -0.7370],\n",
       "          [ 0.0000, -0.0696, -0.0602,  ..., -0.7335, -0.7335, -0.7335],\n",
       "          [ 0.0000, -0.0699, -0.0615,  ..., -0.7394, -0.7394, -0.7394],\n",
       "          ...,\n",
       "          [ 0.0000, -0.1082, -0.1063,  ...,  2.6222,  2.6670,  2.6985],\n",
       "          [ 0.0000, -0.1083, -0.1064,  ...,  2.5999,  2.6442,  2.6790],\n",
       "          [ 0.0000, -0.1085, -0.1066,  ...,  2.5584,  2.6026,  2.6366]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.1042,  0.1704,  ...,  1.0301,  0.9886,  0.9440],\n",
       "          [ 0.0000,  0.0980,  0.1676,  ...,  1.0126,  0.9930,  0.9700],\n",
       "          [ 0.0000,  0.0967,  0.1742,  ...,  1.0366,  1.0012,  0.9635],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0550,  0.0966,  ..., -2.1464, -2.1464, -2.1464],\n",
       "          [ 0.0000,  0.0475,  0.0896,  ..., -2.1405, -2.1405, -2.1405],\n",
       "          [ 0.0000,  0.1659,  0.2936,  ...,  1.6679,  1.5718,  1.4819]],\n",
       "\n",
       "         [[ 0.0000, -0.0931, -0.0887,  ...,  2.6404,  2.6946,  2.7293],\n",
       "          [ 0.0000, -0.0903, -0.0857,  ...,  2.6335,  2.6851,  2.7226],\n",
       "          [ 0.0000, -0.0875, -0.0828,  ...,  2.6422,  2.6906,  2.7261],\n",
       "          ...,\n",
       "          [ 0.0000, -0.1028, -0.1001,  ..., -1.0406, -1.0406, -1.0406],\n",
       "          [ 0.0000, -0.1022, -0.0989,  ..., -1.0403, -1.0403, -1.0403],\n",
       "          [ 0.0000, -0.0981, -0.0955,  ...,  2.4563,  2.4976,  2.5204]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0666,  0.1022,  ...,  0.3090,  0.3176,  0.3292],\n",
       "          [ 0.0000,  0.0654,  0.1013,  ...,  0.3365,  0.3088,  0.2938],\n",
       "          [ 0.0000,  0.2626,  0.4194,  ...,  1.6100,  1.4501,  1.3310],\n",
       "          ...,\n",
       "          [ 0.0000,  0.2579,  0.4144,  ...,  1.1425,  0.9327,  0.7307],\n",
       "          [ 0.0000,  0.2442,  0.4112,  ...,  1.0503,  0.7761,  0.5267],\n",
       "          [ 0.0000,  0.2222,  0.3997,  ...,  1.2079,  0.9882,  0.7786]],\n",
       "\n",
       "         [[ 0.0000, -0.1087, -0.0992,  ...,  1.3608,  1.4005,  1.3968],\n",
       "          [ 0.0000, -0.1096, -0.1000,  ...,  1.3119,  1.3742,  1.4290],\n",
       "          [ 0.0000, -0.2391, -0.2200,  ...,  2.2473,  2.3393,  2.4215],\n",
       "          ...,\n",
       "          [ 0.0000, -0.2476, -0.2341,  ...,  2.0980,  2.1656,  2.2149],\n",
       "          [ 0.0000, -0.2472, -0.2351,  ...,  2.0066,  2.0541,  2.0794],\n",
       "          [ 0.0000, -0.2476, -0.2363,  ...,  2.0554,  2.1071,  2.1384]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0592,  0.1155,  ...,  0.3255,  0.3483,  0.3715],\n",
       "          [ 0.0000,  0.0570,  0.1145,  ...,  0.3224,  0.3434,  0.3743],\n",
       "          [ 0.0000,  0.2089,  0.4274,  ...,  1.1548,  1.0090,  0.9380],\n",
       "          ...,\n",
       "          [ 0.0000,  0.2327,  0.3986,  ...,  0.9069,  0.6735,  0.4415],\n",
       "          [ 0.0000,  0.2326,  0.3967,  ...,  0.9084,  0.6636,  0.4245],\n",
       "          [ 0.0000,  0.2309,  0.3938,  ...,  0.9576,  0.7260,  0.4972]],\n",
       "\n",
       "         [[ 0.0000, -0.1213, -0.1207,  ...,  1.2904,  1.3405,  1.3482],\n",
       "          [ 0.0000, -0.1210, -0.1204,  ...,  1.3038,  1.3483,  1.3504],\n",
       "          [ 0.0000, -0.2356, -0.2355,  ...,  2.2680,  2.3659,  2.4495],\n",
       "          ...,\n",
       "          [ 0.0000, -0.2387, -0.2412,  ...,  2.0891,  2.1274,  2.1384],\n",
       "          [ 0.0000, -0.2351, -0.2373,  ...,  2.0886,  2.1253,  2.1345],\n",
       "          [ 0.0000, -0.2346, -0.2362,  ...,  2.0656,  2.1067,  2.1244]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000,  0.0579,  0.1163,  ...,  0.2855,  0.2676,  0.2716],\n",
       "          [ 0.0000,  0.0549,  0.1134,  ...,  0.3533,  0.3073,  0.2736],\n",
       "          [ 0.0000,  0.1966,  0.4076,  ...,  1.1463,  0.9083,  0.6895],\n",
       "          ...,\n",
       "          [ 0.0000,  0.1969,  0.4202,  ...,  1.1716,  0.9828,  0.8055],\n",
       "          [ 0.0000,  0.1916,  0.4131,  ...,  1.2331,  1.0896,  0.9461],\n",
       "          [ 0.0000,  0.1901,  0.4099,  ...,  1.1520,  0.9682,  0.7848]],\n",
       "\n",
       "         [[ 0.0000, -0.1287, -0.1293,  ...,  1.1518,  1.2109,  1.2564],\n",
       "          [ 0.0000, -0.1312, -0.1320,  ...,  1.1416,  1.1707,  1.1989],\n",
       "          [ 0.0000, -0.2544, -0.2567,  ...,  2.0257,  2.0391,  2.0510],\n",
       "          ...,\n",
       "          [ 0.0000, -0.2772, -0.2839,  ...,  1.9712,  2.0278,  2.0584],\n",
       "          [ 0.0000, -0.2773, -0.2841,  ...,  1.9903,  2.0279,  2.0392],\n",
       "          [ 0.0000, -0.2763, -0.2831,  ...,  1.9935,  2.0455,  2.0634]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch, i in enumerate(batch_xy):\n",
    "    for coord, j in enumerate(i):\n",
    "        for frame, k in enumerate(j):\n",
    "            k = k - k[0]\n",
    "            batch_xy[batch][coord][frame] = k\n",
    "\n",
    "batch_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([501, 2, 25, 67])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0764,  0.1298,  ..., -2.1361, -2.1361, -2.1361],\n",
       "         [ 0.0000,  0.0784,  0.1315,  ..., -2.1408, -2.1408, -2.1408],\n",
       "         [ 0.0000,  0.0824,  0.1324,  ..., -2.1377, -2.1377, -2.1377],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0821,  0.1295,  ..., -2.0772, -2.0772, -2.0772],\n",
       "         [ 0.0000,  0.0829,  0.1306,  ..., -2.0912, -2.0912, -2.0912],\n",
       "         [ 0.0000,  0.0826,  0.1301,  ..., -2.0887, -2.0887, -2.0887]],\n",
       "\n",
       "        [[ 0.0000, -0.1042, -0.1042,  ..., -1.0096, -1.0096, -1.0096],\n",
       "         [ 0.0000, -0.1055, -0.1054,  ..., -1.0186, -1.0186, -1.0186],\n",
       "         [ 0.0000, -0.1071, -0.1069,  ..., -1.0301, -1.0301, -1.0301],\n",
       "         ...,\n",
       "         [ 0.0000, -0.1398, -0.1368,  ..., -1.1023, -1.1023, -1.1023],\n",
       "         [ 0.0000, -0.1401, -0.1372,  ..., -1.1034, -1.1034, -1.1034],\n",
       "         [ 0.0000, -0.1410, -0.1380,  ..., -1.1140, -1.1140, -1.1140]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_xy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([501, 1, 25, 67])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_vi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([501, 2, 25, 67])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.cat((batch_xy, batch_vi), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([501, 3, 25, 67])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Danh sách cần one-hot encode\n",
    "lst = lable_decode\n",
    "\n",
    "# Tạo từ điển ánh xạ chuỗi sang số nguyên\n",
    "unique_labels = list(set(lst))  # Lấy các giá trị duy nhất\n",
    "label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
    "\n",
    "# Chuyển đổi danh sách chuỗi thành danh sách chỉ số\n",
    "indices = [label_to_index[label] for label in lst]\n",
    "\n",
    "# Chuyển danh sách chỉ số thành tensor\n",
    "tensor_indices = torch.tensor(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = len(unique_labels)\n",
    "num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5, 16, 16, 16, 16, 16, 16,\n",
       "        16, 16, 16, 16, 16, 16, 16, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19, 19, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18, 18, 18, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "        23, 23, 23, 23, 23, 23, 23, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
       "        22, 22, 22, 22, 22, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "        17, 17,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4,  4,  4,  4,  4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 21, 21, 21, 21, 21, 21, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9,  9,  9,  9,  9,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 24, 24, 24, 24, 24, 24,\n",
       "        24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 12, 12, 12, 12, 12,\n",
       "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  2,  2, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kết nối khớp cơ thể (Pose Estimation)\n",
    "body_connections = [\n",
    "    (1,4),  \n",
    "    (0,2),  \n",
    "    (1,3), \n",
    "    (2,7),\n",
    "    (0,5), \n",
    "    (6,4),\n",
    "    (8,5), \n",
    "    (3), \n",
    "    (6),\n",
    "    (10),\n",
    "    (9),\n",
    "    (12,13),\n",
    "    (11,14),\n",
    "    (11,15),\n",
    "    (12,16),\n",
    "    (13,17,21),\n",
    "    (14,18,22),\n",
    "    (15,19),\n",
    "    (16,20),\n",
    "    (15,17),\n",
    "    (16,18),\n",
    "    (15,19),\n",
    "    (16),\n",
    "    (24,11),\n",
    "    (12,23),\n",
    "    (26),  \n",
    "    (25, 27),  \n",
    "    (26, 28),  \n",
    "    (27, 29),  \n",
    "    (28),  \n",
    "    (25, 31, 34),  \n",
    "    (30, 32),  \n",
    "    (31, 33),  \n",
    "    (32),  \n",
    "    (30, 38), \n",
    "    (34, 36),\n",
    "    (35, 37),\n",
    "    (36), \n",
    "    (34, 42, 39),\n",
    "    (38, 40),\n",
    "    (39, 41),\n",
    "    (40),\n",
    "    (38, 43),\n",
    "    (42, 44),\n",
    "    (43, 45),\n",
    "    (44),\n",
    "    (47),  \n",
    "    (46, 48),  \n",
    "    (47, 49),  \n",
    "    (48, 50),  \n",
    "    (49),  \n",
    "    (46, 52, 55),  \n",
    "    (51, 53),  \n",
    "    (52, 54),  \n",
    "    (53),  \n",
    "    (51, 59), \n",
    "    (55, 57),\n",
    "    (56, 58),\n",
    "    (57), \n",
    "    (55, 63, 60),\n",
    "    (59, 61),\n",
    "    (60, 62),\n",
    "    (61),\n",
    "    (59, 64),\n",
    "    (63, 65),\n",
    "    (64, 66),\n",
    "    (65)\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(body_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 4), (1, 0), (1, 2), (2, 1), (2, 3), (3, 2), (3, 7), (4, 0), (4, 5), (5, 6), (5, 4), (6, 8), (6, 5), (7, 3), (8, 6), (9, 10), (10, 9), (11, 12), (11, 13), (12, 11), (12, 14), (13, 11), (13, 15), (14, 12), (14, 16), (15, 13), (15, 17), (15, 21), (16, 14), (16, 18), (16, 22), (17, 15), (17, 19), (18, 16), (18, 20), (19, 15), (19, 17), (20, 16), (20, 18), (21, 15), (21, 19), (22, 16), (23, 24), (23, 11), (24, 12), (24, 23), (25, 26), (26, 25), (26, 27), (27, 26), (27, 28), (28, 27), (28, 29), (29, 28), (30, 25), (30, 31), (30, 34), (31, 30), (31, 32), (32, 31), (32, 33), (33, 32), (34, 30), (34, 38), (35, 34), (35, 36), (36, 35), (36, 37), (37, 36), (38, 34), (38, 42), (38, 39), (39, 38), (39, 40), (40, 39), (40, 41), (41, 40), (42, 38), (42, 43), (43, 42), (43, 44), (44, 43), (44, 45), (45, 44), (46, 47), (47, 46), (47, 48), (48, 47), (48, 49), (49, 48), (49, 50), (50, 49), (51, 46), (51, 52), (51, 55), (52, 51), (52, 53), (53, 52), (53, 54), (54, 53), (55, 51), (55, 59), (56, 55), (56, 57), (57, 56), (57, 58), (58, 57), (59, 55), (59, 63), (59, 60), (60, 59), (60, 61), (61, 60), (61, 62), (62, 61), (63, 59), (63, 64), (64, 63), (64, 65), (65, 64), (65, 66), (66, 65)]\n"
     ]
    }
   ],
   "source": [
    "# Tạo danh sách chi tiết hơn theo dạng (index, value)\n",
    "detailed_body_connections = [(i, val) for i, conn in enumerate(body_connections) for val in (conn if isinstance(conn, tuple) else (conn,))]\n",
    "\n",
    "print(detailed_body_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_body_connections = [(0, 1), (0, 4), (1, 0), (1, 2), (2, 1), (2, 3), (3, 2), (3, 7), (4, 0), (4, 5), (5, 6), (5, 4), (6, 8), (6, 5), (7, 3), (8, 6), (9, 10), (10, 9), (11, 12), (11, 13), (12, 11), (12, 14), (13, 11), (13, 15), (14, 12), (14, 16), (15, 13), (15, 17), (15, 21), (16, 14), (16, 18), (16, 22), (17, 15), (17, 19), (18, 16), (18, 20), (19, 15), (19, 17), (20, 16), (20, 18), (21, 15), (21, 19), (22, 16), (23, 24), (23, 11), (24, 12), (24, 23), (25, 26), (26, 25), (26, 27), (27, 26), (27, 28), (28, 27), (28, 29), (29, 28), (30, 25), (30, 31), (30, 34), (31, 30), (31, 32), (32, 31), (32, 33), (33, 32), (34, 30), (34, 38), (35, 34), (35, 36), (36, 35), (36, 37), (37, 36), (38, 34), (38, 42), (38, 39), (39, 38), (39, 40), (40, 39), (40, 41), (41, 40), (42, 38), (42, 43), (43, 42), (43, 44), (44, 43), (44, 45), (45, 44), (46, 47), (47, 46), (47, 48), (48, 47), (48, 49), (49, 48), (49, 50), (50, 49), (51, 46), (51, 52), (51, 55), (52, 51), (52, 53), (53, 52), (53, 54), (54, 53), (55, 51), (55, 59), (56, 55), (56, 57), (57, 56), (57, 58), (58, 57), (59, 55), (59, 63), (59, 60), (60, 59), (60, 61), (61, 60), (61, 62), (62, 61), (63, 59), (63, 64), (64, 63), (64, 65), (65, 64), (65, 66), (66, 65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from STGCN import Model\n",
    "model = Model(in_channels=3, num_nodes=67, inward_edges=detailed_body_connections, n_classes=26, dropout_ratio = 0.1,batch_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "batch_size=5\n",
    "num = len(lable_decode)\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * num)\n",
    "val_size = num - train_size\n",
    "dataset = TensorDataset(batch, tensor_indices)\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Batch [1], Loss: 0.0746\n",
      "Epoch [1/25], Batch [5], Loss: 0.4684\n",
      "Epoch [1/25], Batch [9], Loss: 0.3210\n",
      "Epoch [1/25], Batch [13], Loss: 0.2625\n",
      "Epoch [1/25], Batch [17], Loss: 0.1933\n",
      "Epoch [1/25], Batch [21], Loss: 0.2651\n",
      "Epoch [1/25], Batch [25], Loss: 0.2759\n",
      "Epoch [1/25], Batch [29], Loss: 0.1881\n",
      "Epoch [1/25], Batch [33], Loss: 0.1803\n",
      "Epoch [1/25], Batch [37], Loss: 0.2037\n",
      "Epoch [1/25], Batch [41], Loss: 0.2536\n",
      "Epoch [1/25], Batch [45], Loss: 0.1989\n",
      "Epoch [1/25], Batch [49], Loss: 0.2044\n",
      "Epoch [1/25], Batch [53], Loss: 0.2260\n",
      "Epoch [1/25], Batch [57], Loss: 0.2206\n",
      "Epoch [1/25], Batch [61], Loss: 0.1816\n",
      "Epoch [1/25], Batch [65], Loss: 0.2072\n",
      "Epoch [1/25], Batch [69], Loss: 0.1814\n",
      "Epoch [1/25], Batch [73], Loss: 0.2297\n",
      "Epoch [1/25], Batch [77], Loss: 0.1746\n",
      "Epoch [2/25], Batch [1], Loss: 0.0342\n",
      "Epoch [2/25], Batch [5], Loss: 0.1579\n",
      "Epoch [2/25], Batch [9], Loss: 0.1553\n",
      "Epoch [2/25], Batch [13], Loss: 0.2045\n",
      "Epoch [2/25], Batch [17], Loss: 0.1778\n",
      "Epoch [2/25], Batch [21], Loss: 0.1887\n",
      "Epoch [2/25], Batch [25], Loss: 0.2158\n",
      "Epoch [2/25], Batch [29], Loss: 0.1580\n",
      "Epoch [2/25], Batch [33], Loss: 0.2006\n",
      "Epoch [2/25], Batch [37], Loss: 0.2168\n",
      "Epoch [2/25], Batch [41], Loss: 0.2045\n",
      "Epoch [2/25], Batch [45], Loss: 0.1660\n",
      "Epoch [2/25], Batch [49], Loss: 0.1748\n",
      "Epoch [2/25], Batch [53], Loss: 0.1785\n",
      "Epoch [2/25], Batch [57], Loss: 0.1595\n",
      "Epoch [2/25], Batch [61], Loss: 0.1350\n",
      "Epoch [2/25], Batch [65], Loss: 0.2121\n",
      "Epoch [2/25], Batch [69], Loss: 0.1693\n",
      "Epoch [2/25], Batch [73], Loss: 0.1740\n",
      "Epoch [2/25], Batch [77], Loss: 0.1767\n",
      "Epoch [3/25], Batch [1], Loss: 0.0516\n",
      "Epoch [3/25], Batch [5], Loss: 0.1719\n",
      "Epoch [3/25], Batch [9], Loss: 0.1705\n",
      "Epoch [3/25], Batch [13], Loss: 0.1697\n",
      "Epoch [3/25], Batch [17], Loss: 0.1224\n",
      "Epoch [3/25], Batch [21], Loss: 0.1644\n",
      "Epoch [3/25], Batch [25], Loss: 0.1526\n",
      "Epoch [3/25], Batch [29], Loss: 0.1398\n",
      "Epoch [3/25], Batch [33], Loss: 0.1449\n",
      "Epoch [3/25], Batch [37], Loss: 0.1374\n",
      "Epoch [3/25], Batch [41], Loss: 0.1513\n",
      "Epoch [3/25], Batch [45], Loss: 0.1605\n",
      "Epoch [3/25], Batch [49], Loss: 0.1798\n",
      "Epoch [3/25], Batch [53], Loss: 0.1453\n",
      "Epoch [3/25], Batch [57], Loss: 0.1734\n",
      "Epoch [3/25], Batch [61], Loss: 0.1793\n",
      "Epoch [3/25], Batch [65], Loss: 0.1799\n",
      "Epoch [3/25], Batch [69], Loss: 0.2069\n",
      "Epoch [3/25], Batch [73], Loss: 0.1550\n",
      "Epoch [3/25], Batch [77], Loss: 0.1515\n",
      "Epoch [4/25], Batch [1], Loss: 0.0268\n",
      "Epoch [4/25], Batch [5], Loss: 0.1643\n",
      "Epoch [4/25], Batch [9], Loss: 0.1525\n",
      "Epoch [4/25], Batch [13], Loss: 0.1434\n",
      "Epoch [4/25], Batch [17], Loss: 0.1534\n",
      "Epoch [4/25], Batch [21], Loss: 0.1937\n",
      "Epoch [4/25], Batch [25], Loss: 0.2002\n",
      "Epoch [4/25], Batch [29], Loss: 0.1471\n",
      "Epoch [4/25], Batch [33], Loss: 0.1758\n",
      "Epoch [4/25], Batch [37], Loss: 0.1804\n",
      "Epoch [4/25], Batch [41], Loss: 0.1214\n",
      "Epoch [4/25], Batch [45], Loss: 0.1578\n",
      "Epoch [4/25], Batch [49], Loss: 0.1254\n",
      "Epoch [4/25], Batch [53], Loss: 0.1474\n",
      "Epoch [4/25], Batch [57], Loss: 0.1692\n",
      "Epoch [4/25], Batch [61], Loss: 0.1142\n",
      "Epoch [4/25], Batch [65], Loss: 0.1489\n",
      "Epoch [4/25], Batch [69], Loss: 0.1824\n",
      "Epoch [4/25], Batch [73], Loss: 0.1386\n",
      "Epoch [4/25], Batch [77], Loss: 0.1483\n",
      "Epoch [5/25], Batch [1], Loss: 0.0610\n",
      "Epoch [5/25], Batch [5], Loss: 0.1589\n",
      "Epoch [5/25], Batch [9], Loss: 0.1378\n",
      "Epoch [5/25], Batch [13], Loss: 0.1373\n",
      "Epoch [5/25], Batch [17], Loss: 0.1707\n",
      "Epoch [5/25], Batch [21], Loss: 0.1260\n",
      "Epoch [5/25], Batch [25], Loss: 0.1209\n",
      "Epoch [5/25], Batch [29], Loss: 0.1531\n",
      "Epoch [5/25], Batch [33], Loss: 0.1523\n",
      "Epoch [5/25], Batch [37], Loss: 0.1553\n",
      "Epoch [5/25], Batch [41], Loss: 0.1000\n",
      "Epoch [5/25], Batch [45], Loss: 0.1134\n",
      "Epoch [5/25], Batch [49], Loss: 0.1246\n",
      "Epoch [5/25], Batch [53], Loss: 0.1673\n",
      "Epoch [5/25], Batch [57], Loss: 0.1624\n",
      "Epoch [5/25], Batch [61], Loss: 0.1488\n",
      "Epoch [5/25], Batch [65], Loss: 0.1474\n",
      "Epoch [5/25], Batch [69], Loss: 0.1792\n",
      "Epoch [5/25], Batch [73], Loss: 0.1144\n",
      "Epoch [5/25], Batch [77], Loss: 0.1325\n",
      "Epoch [6/25], Batch [1], Loss: 0.0418\n",
      "Epoch [6/25], Batch [5], Loss: 0.0931\n",
      "Epoch [6/25], Batch [9], Loss: 0.1460\n",
      "Epoch [6/25], Batch [13], Loss: 0.1835\n",
      "Epoch [6/25], Batch [17], Loss: 0.1331\n",
      "Epoch [6/25], Batch [21], Loss: 0.1409\n",
      "Epoch [6/25], Batch [25], Loss: 0.1349\n",
      "Epoch [6/25], Batch [29], Loss: 0.1868\n",
      "Epoch [6/25], Batch [33], Loss: 0.1631\n",
      "Epoch [6/25], Batch [37], Loss: 0.1384\n",
      "Epoch [6/25], Batch [41], Loss: 0.1656\n",
      "Epoch [6/25], Batch [45], Loss: 0.1282\n",
      "Epoch [6/25], Batch [49], Loss: 0.1354\n",
      "Epoch [6/25], Batch [53], Loss: 0.1373\n",
      "Epoch [6/25], Batch [57], Loss: 0.1296\n",
      "Epoch [6/25], Batch [61], Loss: 0.1584\n",
      "Epoch [6/25], Batch [65], Loss: 0.1367\n",
      "Epoch [6/25], Batch [69], Loss: 0.1112\n",
      "Epoch [6/25], Batch [73], Loss: 0.1237\n",
      "Epoch [6/25], Batch [77], Loss: 0.1267\n",
      "Epoch [7/25], Batch [1], Loss: 0.0252\n",
      "Epoch [7/25], Batch [5], Loss: 0.1154\n",
      "Epoch [7/25], Batch [9], Loss: 0.1046\n",
      "Epoch [7/25], Batch [13], Loss: 0.1032\n",
      "Epoch [7/25], Batch [17], Loss: 0.1480\n",
      "Epoch [7/25], Batch [21], Loss: 0.1387\n",
      "Epoch [7/25], Batch [25], Loss: 0.1052\n",
      "Epoch [7/25], Batch [29], Loss: 0.1711\n",
      "Epoch [7/25], Batch [33], Loss: 0.1218\n",
      "Epoch [7/25], Batch [37], Loss: 0.1146\n",
      "Epoch [7/25], Batch [41], Loss: 0.1350\n",
      "Epoch [7/25], Batch [45], Loss: 0.1314\n",
      "Epoch [7/25], Batch [49], Loss: 0.1448\n",
      "Epoch [7/25], Batch [53], Loss: 0.1203\n",
      "Epoch [7/25], Batch [57], Loss: 0.1531\n",
      "Epoch [7/25], Batch [61], Loss: 0.1298\n",
      "Epoch [7/25], Batch [65], Loss: 0.1313\n",
      "Epoch [7/25], Batch [69], Loss: 0.1390\n",
      "Epoch [7/25], Batch [73], Loss: 0.1620\n",
      "Epoch [7/25], Batch [77], Loss: 0.1247\n",
      "Epoch [8/25], Batch [1], Loss: 0.0408\n",
      "Epoch [8/25], Batch [5], Loss: 0.1419\n",
      "Epoch [8/25], Batch [9], Loss: 0.0944\n",
      "Epoch [8/25], Batch [13], Loss: 0.1862\n",
      "Epoch [8/25], Batch [17], Loss: 0.0963\n",
      "Epoch [8/25], Batch [21], Loss: 0.0850\n",
      "Epoch [8/25], Batch [25], Loss: 0.0775\n",
      "Epoch [8/25], Batch [29], Loss: 0.1354\n",
      "Epoch [8/25], Batch [33], Loss: 0.1143\n",
      "Epoch [8/25], Batch [37], Loss: 0.0776\n",
      "Epoch [8/25], Batch [41], Loss: 0.1369\n",
      "Epoch [8/25], Batch [45], Loss: 0.0878\n",
      "Epoch [8/25], Batch [49], Loss: 0.1314\n",
      "Epoch [8/25], Batch [53], Loss: 0.0986\n",
      "Epoch [8/25], Batch [57], Loss: 0.1101\n",
      "Epoch [8/25], Batch [61], Loss: 0.1569\n",
      "Epoch [8/25], Batch [65], Loss: 0.1349\n",
      "Epoch [8/25], Batch [69], Loss: 0.1359\n",
      "Epoch [8/25], Batch [73], Loss: 0.1311\n",
      "Epoch [8/25], Batch [77], Loss: 0.0950\n",
      "Epoch [9/25], Batch [1], Loss: 0.0376\n",
      "Epoch [9/25], Batch [5], Loss: 0.1011\n",
      "Epoch [9/25], Batch [9], Loss: 0.1118\n",
      "Epoch [9/25], Batch [13], Loss: 0.1658\n",
      "Epoch [9/25], Batch [17], Loss: 0.1544\n",
      "Epoch [9/25], Batch [21], Loss: 0.1454\n",
      "Epoch [9/25], Batch [25], Loss: 0.0733\n",
      "Epoch [9/25], Batch [29], Loss: 0.1253\n",
      "Epoch [9/25], Batch [33], Loss: 0.1224\n",
      "Epoch [9/25], Batch [37], Loss: 0.0871\n",
      "Epoch [9/25], Batch [41], Loss: 0.1280\n",
      "Epoch [9/25], Batch [45], Loss: 0.0718\n",
      "Epoch [9/25], Batch [49], Loss: 0.1405\n",
      "Epoch [9/25], Batch [53], Loss: 0.1144\n",
      "Epoch [9/25], Batch [57], Loss: 0.1273\n",
      "Epoch [9/25], Batch [61], Loss: 0.1189\n",
      "Epoch [9/25], Batch [65], Loss: 0.1135\n",
      "Epoch [9/25], Batch [69], Loss: 0.0730\n",
      "Epoch [9/25], Batch [73], Loss: 0.0748\n",
      "Epoch [9/25], Batch [77], Loss: 0.1350\n",
      "Epoch [10/25], Batch [1], Loss: 0.0517\n",
      "Epoch [10/25], Batch [5], Loss: 0.1531\n",
      "Epoch [10/25], Batch [9], Loss: 0.0950\n",
      "Epoch [10/25], Batch [13], Loss: 0.1233\n",
      "Epoch [10/25], Batch [17], Loss: 0.1468\n",
      "Epoch [10/25], Batch [21], Loss: 0.1075\n",
      "Epoch [10/25], Batch [25], Loss: 0.1125\n",
      "Epoch [10/25], Batch [29], Loss: 0.1021\n",
      "Epoch [10/25], Batch [33], Loss: 0.1421\n",
      "Epoch [10/25], Batch [37], Loss: 0.0738\n",
      "Epoch [10/25], Batch [41], Loss: 0.1177\n",
      "Epoch [10/25], Batch [45], Loss: 0.1469\n",
      "Epoch [10/25], Batch [49], Loss: 0.1140\n",
      "Epoch [10/25], Batch [53], Loss: 0.1323\n",
      "Epoch [10/25], Batch [57], Loss: 0.1138\n",
      "Epoch [10/25], Batch [61], Loss: 0.1075\n",
      "Epoch [10/25], Batch [65], Loss: 0.1061\n",
      "Epoch [10/25], Batch [69], Loss: 0.1011\n",
      "Epoch [10/25], Batch [73], Loss: 0.1020\n",
      "Epoch [10/25], Batch [77], Loss: 0.1473\n",
      "Epoch [11/25], Batch [1], Loss: 0.0252\n",
      "Epoch [11/25], Batch [5], Loss: 0.1245\n",
      "Epoch [11/25], Batch [9], Loss: 0.1130\n",
      "Epoch [11/25], Batch [13], Loss: 0.1010\n",
      "Epoch [11/25], Batch [17], Loss: 0.1642\n",
      "Epoch [11/25], Batch [21], Loss: 0.1083\n",
      "Epoch [11/25], Batch [25], Loss: 0.1719\n",
      "Epoch [11/25], Batch [29], Loss: 0.1099\n",
      "Epoch [11/25], Batch [33], Loss: 0.0927\n",
      "Epoch [11/25], Batch [37], Loss: 0.0731\n",
      "Epoch [11/25], Batch [41], Loss: 0.1184\n",
      "Epoch [11/25], Batch [45], Loss: 0.1358\n",
      "Epoch [11/25], Batch [49], Loss: 0.1034\n",
      "Epoch [11/25], Batch [53], Loss: 0.1331\n",
      "Epoch [11/25], Batch [57], Loss: 0.1298\n",
      "Epoch [11/25], Batch [61], Loss: 0.1221\n",
      "Epoch [11/25], Batch [65], Loss: 0.1428\n",
      "Epoch [11/25], Batch [69], Loss: 0.1075\n",
      "Epoch [11/25], Batch [73], Loss: 0.0526\n",
      "Epoch [11/25], Batch [77], Loss: 0.1522\n",
      "Epoch [12/25], Batch [1], Loss: 0.0330\n",
      "Epoch [12/25], Batch [5], Loss: 0.0833\n",
      "Epoch [12/25], Batch [9], Loss: 0.1233\n",
      "Epoch [12/25], Batch [13], Loss: 0.1284\n",
      "Epoch [12/25], Batch [17], Loss: 0.1004\n",
      "Epoch [12/25], Batch [21], Loss: 0.1280\n",
      "Epoch [12/25], Batch [25], Loss: 0.0968\n",
      "Epoch [12/25], Batch [29], Loss: 0.0963\n",
      "Epoch [12/25], Batch [33], Loss: 0.1123\n",
      "Epoch [12/25], Batch [37], Loss: 0.0926\n",
      "Epoch [12/25], Batch [41], Loss: 0.1127\n",
      "Epoch [12/25], Batch [45], Loss: 0.1016\n",
      "Epoch [12/25], Batch [49], Loss: 0.0779\n",
      "Epoch [12/25], Batch [53], Loss: 0.1456\n",
      "Epoch [12/25], Batch [57], Loss: 0.0988\n",
      "Epoch [12/25], Batch [61], Loss: 0.1084\n",
      "Epoch [12/25], Batch [65], Loss: 0.0780\n",
      "Epoch [12/25], Batch [69], Loss: 0.0866\n",
      "Epoch [12/25], Batch [73], Loss: 0.0940\n",
      "Epoch [12/25], Batch [77], Loss: 0.0996\n",
      "Epoch [13/25], Batch [1], Loss: 0.0310\n",
      "Epoch [13/25], Batch [5], Loss: 0.0777\n",
      "Epoch [13/25], Batch [9], Loss: 0.0748\n",
      "Epoch [13/25], Batch [13], Loss: 0.1238\n",
      "Epoch [13/25], Batch [17], Loss: 0.0838\n",
      "Epoch [13/25], Batch [21], Loss: 0.0682\n",
      "Epoch [13/25], Batch [25], Loss: 0.0961\n",
      "Epoch [13/25], Batch [29], Loss: 0.0926\n",
      "Epoch [13/25], Batch [33], Loss: 0.0698\n",
      "Epoch [13/25], Batch [37], Loss: 0.1215\n",
      "Epoch [13/25], Batch [41], Loss: 0.0963\n",
      "Epoch [13/25], Batch [45], Loss: 0.0799\n",
      "Epoch [13/25], Batch [49], Loss: 0.1024\n",
      "Epoch [13/25], Batch [53], Loss: 0.0470\n",
      "Epoch [13/25], Batch [57], Loss: 0.0894\n",
      "Epoch [13/25], Batch [61], Loss: 0.0888\n",
      "Epoch [13/25], Batch [65], Loss: 0.1181\n",
      "Epoch [13/25], Batch [69], Loss: 0.0910\n",
      "Epoch [13/25], Batch [73], Loss: 0.1107\n",
      "Epoch [13/25], Batch [77], Loss: 0.0871\n",
      "Epoch [14/25], Batch [1], Loss: 0.0192\n",
      "Epoch [14/25], Batch [5], Loss: 0.1218\n",
      "Epoch [14/25], Batch [9], Loss: 0.0666\n",
      "Epoch [14/25], Batch [13], Loss: 0.1016\n",
      "Epoch [14/25], Batch [17], Loss: 0.1433\n",
      "Epoch [14/25], Batch [21], Loss: 0.0917\n",
      "Epoch [14/25], Batch [25], Loss: 0.1061\n",
      "Epoch [14/25], Batch [29], Loss: 0.1010\n",
      "Epoch [14/25], Batch [33], Loss: 0.0740\n",
      "Epoch [14/25], Batch [37], Loss: 0.1508\n",
      "Epoch [14/25], Batch [41], Loss: 0.0703\n",
      "Epoch [14/25], Batch [45], Loss: 0.0466\n",
      "Epoch [14/25], Batch [49], Loss: 0.0759\n",
      "Epoch [14/25], Batch [53], Loss: 0.0958\n",
      "Epoch [14/25], Batch [57], Loss: 0.0940\n",
      "Epoch [14/25], Batch [61], Loss: 0.1079\n",
      "Epoch [14/25], Batch [65], Loss: 0.1251\n",
      "Epoch [14/25], Batch [69], Loss: 0.0963\n",
      "Epoch [14/25], Batch [73], Loss: 0.0877\n",
      "Epoch [14/25], Batch [77], Loss: 0.1026\n",
      "Epoch [15/25], Batch [1], Loss: 0.0429\n",
      "Epoch [15/25], Batch [5], Loss: 0.0664\n",
      "Epoch [15/25], Batch [9], Loss: 0.0744\n",
      "Epoch [15/25], Batch [13], Loss: 0.1336\n",
      "Epoch [15/25], Batch [17], Loss: 0.0749\n",
      "Epoch [15/25], Batch [21], Loss: 0.0885\n",
      "Epoch [15/25], Batch [25], Loss: 0.0856\n",
      "Epoch [15/25], Batch [29], Loss: 0.1288\n",
      "Epoch [15/25], Batch [33], Loss: 0.1004\n",
      "Epoch [15/25], Batch [37], Loss: 0.1181\n",
      "Epoch [15/25], Batch [41], Loss: 0.0907\n",
      "Epoch [15/25], Batch [45], Loss: 0.1027\n",
      "Epoch [15/25], Batch [49], Loss: 0.1102\n",
      "Epoch [15/25], Batch [53], Loss: 0.0694\n",
      "Epoch [15/25], Batch [57], Loss: 0.1270\n",
      "Epoch [15/25], Batch [61], Loss: 0.0874\n",
      "Epoch [15/25], Batch [65], Loss: 0.0814\n",
      "Epoch [15/25], Batch [69], Loss: 0.1575\n",
      "Epoch [15/25], Batch [73], Loss: 0.0729\n",
      "Epoch [15/25], Batch [77], Loss: 0.1431\n",
      "Epoch [16/25], Batch [1], Loss: 0.0249\n",
      "Epoch [16/25], Batch [5], Loss: 0.0625\n",
      "Epoch [16/25], Batch [9], Loss: 0.1067\n",
      "Epoch [16/25], Batch [13], Loss: 0.0588\n",
      "Epoch [16/25], Batch [17], Loss: 0.0722\n",
      "Epoch [16/25], Batch [21], Loss: 0.0753\n",
      "Epoch [16/25], Batch [25], Loss: 0.0913\n",
      "Epoch [16/25], Batch [29], Loss: 0.0771\n",
      "Epoch [16/25], Batch [33], Loss: 0.0953\n",
      "Epoch [16/25], Batch [37], Loss: 0.0773\n",
      "Epoch [16/25], Batch [41], Loss: 0.1414\n",
      "Epoch [16/25], Batch [45], Loss: 0.1004\n",
      "Epoch [16/25], Batch [49], Loss: 0.0894\n",
      "Epoch [16/25], Batch [53], Loss: 0.0681\n",
      "Epoch [16/25], Batch [57], Loss: 0.0840\n",
      "Epoch [16/25], Batch [61], Loss: 0.0794\n",
      "Epoch [16/25], Batch [65], Loss: 0.0826\n",
      "Epoch [16/25], Batch [69], Loss: 0.1184\n",
      "Epoch [16/25], Batch [73], Loss: 0.0955\n",
      "Epoch [16/25], Batch [77], Loss: 0.0599\n",
      "Epoch [17/25], Batch [1], Loss: 0.0251\n",
      "Epoch [17/25], Batch [5], Loss: 0.0664\n",
      "Epoch [17/25], Batch [9], Loss: 0.0783\n",
      "Epoch [17/25], Batch [13], Loss: 0.0934\n",
      "Epoch [17/25], Batch [17], Loss: 0.0759\n",
      "Epoch [17/25], Batch [21], Loss: 0.0710\n",
      "Epoch [17/25], Batch [25], Loss: 0.0832\n",
      "Epoch [17/25], Batch [29], Loss: 0.1181\n",
      "Epoch [17/25], Batch [33], Loss: 0.0715\n",
      "Epoch [17/25], Batch [37], Loss: 0.0869\n",
      "Epoch [17/25], Batch [41], Loss: 0.0512\n",
      "Epoch [17/25], Batch [45], Loss: 0.0814\n",
      "Epoch [17/25], Batch [49], Loss: 0.1313\n",
      "Epoch [17/25], Batch [53], Loss: 0.0681\n",
      "Epoch [17/25], Batch [57], Loss: 0.0859\n",
      "Epoch [17/25], Batch [61], Loss: 0.0901\n",
      "Epoch [17/25], Batch [65], Loss: 0.0940\n",
      "Epoch [17/25], Batch [69], Loss: 0.0602\n",
      "Epoch [17/25], Batch [73], Loss: 0.0772\n",
      "Epoch [17/25], Batch [77], Loss: 0.1175\n",
      "Epoch [18/25], Batch [1], Loss: 0.0287\n",
      "Epoch [18/25], Batch [5], Loss: 0.0900\n",
      "Epoch [18/25], Batch [9], Loss: 0.0858\n",
      "Epoch [18/25], Batch [13], Loss: 0.0697\n",
      "Epoch [18/25], Batch [17], Loss: 0.0638\n",
      "Epoch [18/25], Batch [21], Loss: 0.0538\n",
      "Epoch [18/25], Batch [25], Loss: 0.1217\n",
      "Epoch [18/25], Batch [29], Loss: 0.0593\n",
      "Epoch [18/25], Batch [33], Loss: 0.1096\n",
      "Epoch [18/25], Batch [37], Loss: 0.1150\n",
      "Epoch [18/25], Batch [41], Loss: 0.1021\n",
      "Epoch [18/25], Batch [45], Loss: 0.0906\n",
      "Epoch [18/25], Batch [49], Loss: 0.0767\n",
      "Epoch [18/25], Batch [53], Loss: 0.0912\n",
      "Epoch [18/25], Batch [57], Loss: 0.1089\n",
      "Epoch [18/25], Batch [61], Loss: 0.0686\n",
      "Epoch [18/25], Batch [65], Loss: 0.0499\n",
      "Epoch [18/25], Batch [69], Loss: 0.0686\n",
      "Epoch [18/25], Batch [73], Loss: 0.0781\n",
      "Epoch [18/25], Batch [77], Loss: 0.0394\n",
      "Epoch [19/25], Batch [1], Loss: 0.0107\n",
      "Epoch [19/25], Batch [5], Loss: 0.0547\n",
      "Epoch [19/25], Batch [9], Loss: 0.0801\n",
      "Epoch [19/25], Batch [13], Loss: 0.0388\n",
      "Epoch [19/25], Batch [17], Loss: 0.1025\n",
      "Epoch [19/25], Batch [21], Loss: 0.0875\n",
      "Epoch [19/25], Batch [25], Loss: 0.0694\n",
      "Epoch [19/25], Batch [29], Loss: 0.1113\n",
      "Epoch [19/25], Batch [33], Loss: 0.0738\n",
      "Epoch [19/25], Batch [37], Loss: 0.0611\n",
      "Epoch [19/25], Batch [41], Loss: 0.0931\n",
      "Epoch [19/25], Batch [45], Loss: 0.0772\n",
      "Epoch [19/25], Batch [49], Loss: 0.0949\n",
      "Epoch [19/25], Batch [53], Loss: 0.0493\n",
      "Epoch [19/25], Batch [57], Loss: 0.0768\n",
      "Epoch [19/25], Batch [61], Loss: 0.0710\n",
      "Epoch [19/25], Batch [65], Loss: 0.0942\n",
      "Epoch [19/25], Batch [69], Loss: 0.0908\n",
      "Epoch [19/25], Batch [73], Loss: 0.0670\n",
      "Epoch [19/25], Batch [77], Loss: 0.0839\n",
      "Epoch [20/25], Batch [1], Loss: 0.0112\n",
      "Epoch [20/25], Batch [5], Loss: 0.0848\n",
      "Epoch [20/25], Batch [9], Loss: 0.0723\n",
      "Epoch [20/25], Batch [13], Loss: 0.1146\n",
      "Epoch [20/25], Batch [17], Loss: 0.0689\n",
      "Epoch [20/25], Batch [21], Loss: 0.0959\n",
      "Epoch [20/25], Batch [25], Loss: 0.0436\n",
      "Epoch [20/25], Batch [29], Loss: 0.1236\n",
      "Epoch [20/25], Batch [33], Loss: 0.0676\n",
      "Epoch [20/25], Batch [37], Loss: 0.0607\n",
      "Epoch [20/25], Batch [41], Loss: 0.0780\n",
      "Epoch [20/25], Batch [45], Loss: 0.0590\n",
      "Epoch [20/25], Batch [49], Loss: 0.0609\n",
      "Epoch [20/25], Batch [53], Loss: 0.0503\n",
      "Epoch [20/25], Batch [57], Loss: 0.0940\n",
      "Epoch [20/25], Batch [61], Loss: 0.0933\n",
      "Epoch [20/25], Batch [65], Loss: 0.0717\n",
      "Epoch [20/25], Batch [69], Loss: 0.0794\n",
      "Epoch [20/25], Batch [73], Loss: 0.0674\n",
      "Epoch [20/25], Batch [77], Loss: 0.1013\n",
      "Epoch [21/25], Batch [1], Loss: 0.0141\n",
      "Epoch [21/25], Batch [5], Loss: 0.0654\n",
      "Epoch [21/25], Batch [9], Loss: 0.0671\n",
      "Epoch [21/25], Batch [13], Loss: 0.0388\n",
      "Epoch [21/25], Batch [17], Loss: 0.1232\n",
      "Epoch [21/25], Batch [21], Loss: 0.0897\n",
      "Epoch [21/25], Batch [25], Loss: 0.1045\n",
      "Epoch [21/25], Batch [29], Loss: 0.0538\n",
      "Epoch [21/25], Batch [33], Loss: 0.0502\n",
      "Epoch [21/25], Batch [37], Loss: 0.0844\n",
      "Epoch [21/25], Batch [41], Loss: 0.0881\n",
      "Epoch [21/25], Batch [45], Loss: 0.0681\n",
      "Epoch [21/25], Batch [49], Loss: 0.0968\n",
      "Epoch [21/25], Batch [53], Loss: 0.0833\n",
      "Epoch [21/25], Batch [57], Loss: 0.0584\n",
      "Epoch [21/25], Batch [61], Loss: 0.0787\n",
      "Epoch [21/25], Batch [65], Loss: 0.0584\n",
      "Epoch [21/25], Batch [69], Loss: 0.0696\n",
      "Epoch [21/25], Batch [73], Loss: 0.0531\n",
      "Epoch [21/25], Batch [77], Loss: 0.0667\n",
      "Epoch [22/25], Batch [1], Loss: 0.0340\n",
      "Epoch [22/25], Batch [5], Loss: 0.0699\n",
      "Epoch [22/25], Batch [9], Loss: 0.0528\n",
      "Epoch [22/25], Batch [13], Loss: 0.0803\n",
      "Epoch [22/25], Batch [17], Loss: 0.0891\n",
      "Epoch [22/25], Batch [21], Loss: 0.0291\n",
      "Epoch [22/25], Batch [25], Loss: 0.0976\n",
      "Epoch [22/25], Batch [29], Loss: 0.0792\n",
      "Epoch [22/25], Batch [33], Loss: 0.0675\n",
      "Epoch [22/25], Batch [37], Loss: 0.0779\n",
      "Epoch [22/25], Batch [41], Loss: 0.0490\n",
      "Epoch [22/25], Batch [45], Loss: 0.0650\n",
      "Epoch [22/25], Batch [49], Loss: 0.1116\n",
      "Epoch [22/25], Batch [53], Loss: 0.1008\n",
      "Epoch [22/25], Batch [57], Loss: 0.0530\n",
      "Epoch [22/25], Batch [61], Loss: 0.1116\n",
      "Epoch [22/25], Batch [65], Loss: 0.0587\n",
      "Epoch [22/25], Batch [69], Loss: 0.0445\n",
      "Epoch [22/25], Batch [73], Loss: 0.1198\n",
      "Epoch [22/25], Batch [77], Loss: 0.0883\n",
      "Epoch [23/25], Batch [1], Loss: 0.0058\n",
      "Epoch [23/25], Batch [5], Loss: 0.0538\n",
      "Epoch [23/25], Batch [9], Loss: 0.1028\n",
      "Epoch [23/25], Batch [13], Loss: 0.1161\n",
      "Epoch [23/25], Batch [17], Loss: 0.0539\n",
      "Epoch [23/25], Batch [21], Loss: 0.0516\n",
      "Epoch [23/25], Batch [25], Loss: 0.0808\n",
      "Epoch [23/25], Batch [29], Loss: 0.0856\n",
      "Epoch [23/25], Batch [33], Loss: 0.0898\n",
      "Epoch [23/25], Batch [37], Loss: 0.0566\n",
      "Epoch [23/25], Batch [41], Loss: 0.0973\n",
      "Epoch [23/25], Batch [45], Loss: 0.0953\n",
      "Epoch [23/25], Batch [49], Loss: 0.0247\n",
      "Epoch [23/25], Batch [53], Loss: 0.0870\n",
      "Epoch [23/25], Batch [57], Loss: 0.0628\n",
      "Epoch [23/25], Batch [61], Loss: 0.0604\n",
      "Epoch [23/25], Batch [65], Loss: 0.1254\n",
      "Epoch [23/25], Batch [69], Loss: 0.1005\n",
      "Epoch [23/25], Batch [73], Loss: 0.0738\n",
      "Epoch [23/25], Batch [77], Loss: 0.0673\n",
      "Epoch [24/25], Batch [1], Loss: 0.0205\n",
      "Epoch [24/25], Batch [5], Loss: 0.0503\n",
      "Epoch [24/25], Batch [9], Loss: 0.0762\n",
      "Epoch [24/25], Batch [13], Loss: 0.0594\n",
      "Epoch [24/25], Batch [17], Loss: 0.0668\n",
      "Epoch [24/25], Batch [21], Loss: 0.0669\n",
      "Epoch [24/25], Batch [25], Loss: 0.0745\n",
      "Epoch [24/25], Batch [29], Loss: 0.0494\n",
      "Epoch [24/25], Batch [33], Loss: 0.0911\n",
      "Epoch [24/25], Batch [37], Loss: 0.0663\n",
      "Epoch [24/25], Batch [41], Loss: 0.0332\n",
      "Epoch [24/25], Batch [45], Loss: 0.0521\n",
      "Epoch [24/25], Batch [49], Loss: 0.0612\n",
      "Epoch [24/25], Batch [53], Loss: 0.0978\n",
      "Epoch [24/25], Batch [57], Loss: 0.0760\n",
      "Epoch [24/25], Batch [61], Loss: 0.0993\n",
      "Epoch [24/25], Batch [65], Loss: 0.0540\n",
      "Epoch [24/25], Batch [69], Loss: 0.0455\n",
      "Epoch [24/25], Batch [73], Loss: 0.0847\n",
      "Epoch [24/25], Batch [77], Loss: 0.0681\n",
      "Epoch [25/25], Batch [1], Loss: 0.0142\n",
      "Epoch [25/25], Batch [5], Loss: 0.0770\n",
      "Epoch [25/25], Batch [9], Loss: 0.0661\n",
      "Epoch [25/25], Batch [13], Loss: 0.0559\n",
      "Epoch [25/25], Batch [17], Loss: 0.0613\n",
      "Epoch [25/25], Batch [21], Loss: 0.0772\n",
      "Epoch [25/25], Batch [25], Loss: 0.0292\n",
      "Epoch [25/25], Batch [29], Loss: 0.1148\n",
      "Epoch [25/25], Batch [33], Loss: 0.0661\n",
      "Epoch [25/25], Batch [37], Loss: 0.0914\n",
      "Epoch [25/25], Batch [41], Loss: 0.0696\n",
      "Epoch [25/25], Batch [45], Loss: 0.0698\n",
      "Epoch [25/25], Batch [49], Loss: 0.0798\n",
      "Epoch [25/25], Batch [53], Loss: 0.0239\n",
      "Epoch [25/25], Batch [57], Loss: 0.0661\n",
      "Epoch [25/25], Batch [61], Loss: 0.0620\n",
      "Epoch [25/25], Batch [65], Loss: 0.0594\n",
      "Epoch [25/25], Batch [69], Loss: 0.0540\n",
      "Epoch [25/25], Batch [73], Loss: 0.1231\n",
      "Epoch [25/25], Batch [77], Loss: 0.1193\n",
      "Hoàn thành huấn luyện!\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "num_epochs = 25\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs, labels\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass và cập nhật trọng số\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # In ra thông tin sau mỗi 100 batch\n",
    "        running_loss += loss.item()\n",
    "        if i  % 4 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}], Loss: {running_loss/100:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Hoàn thành huấn luyện!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.25%\n",
      "Precision: 0.82\n",
      "Recall: 0.76\n",
      "F1 Score: 0.76\n",
      "Confusion Matrix:\n",
      "[[26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0 17  0  1  0  4  0  0  2  0  0  0  0  1  2  0  0  0  1  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0 13  0  0  3  0  1  0  1  0  4  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0 11  0 11  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "   2  0]\n",
      " [ 0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0 11  0  0  0  0  0  1  0  0  0  0  0  0  0  0  2\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  1  0  0  1  6\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0 11  0  0  0  0  0  0  0  0  0  0  6  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  8  0  6  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 22  3  0  0  0  0  4  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  1  0  0  0  3  0  0  2  0  0  0  1  0 10  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  3  0  1  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0 13  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 11  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 17  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  5  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  14  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0\n",
      "   0  4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Semester_7\\GraduationProject\\SLR\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Giả sử bạn đã có mô hình đã huấn luyện và test_loader là DataLoader cho tập test\n",
    "# Chúng ta sẽ tạo danh sách để lưu trữ các nhãn dự đoán và nhãn thực tế\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Đánh giá mô hình trên tập test\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Đặt mô hình ở chế độ đánh giá\n",
    "    for data, labels in train_dataset:\n",
    "        data = data.unsqueeze(0)\n",
    "        outputs = model(data)  # Dự đoán từ mô hình\n",
    "        predicted_classes = torch.argmax(outputs, dim=1)  # Lấy nhãn có xác suất cao nhất\n",
    "        all_preds.extend(predicted_classes.numpy())  # Thêm nhãn dự đoán vào danh sách\n",
    "        all_labels.extend(labels.unsqueeze(0).numpy())  # Thêm nhãn thực tế vào danh sách\n",
    "\n",
    "# Tính toán các chỉ số đánh giá\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')  # Tính precision cho đa lớp\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')  # Tính recall cho đa lớp\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')  # Tính F1-score cho đa lớp\n",
    "confusion = confusion_matrix(all_labels, all_preds)  # Tính confusion matrix\n",
    "\n",
    "# In ra các kết quả đánh giá\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.30%\n",
      "Precision: 0.69\n",
      "Recall: 0.70\n",
      "F1 Score: 0.67\n",
      "Confusion Matrix:\n",
      "[[7 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 4 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 4 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [1 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 8 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Semester_7\\GraduationProject\\SLR\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Giả sử bạn đã có mô hình đã huấn luyện và test_loader là DataLoader cho tập test\n",
    "# Chúng ta sẽ tạo danh sách để lưu trữ các nhãn dự đoán và nhãn thực tế\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Đánh giá mô hình trên tập test\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Đặt mô hình ở chế độ đánh giá\n",
    "    for data, labels in val_dataset:\n",
    "        data = data.unsqueeze(0)\n",
    "        outputs = model(data)  # Dự đoán từ mô hình\n",
    "        predicted_classes = torch.argmax(outputs, dim=1)  # Lấy nhãn có xác suất cao nhất\n",
    "        all_preds.extend(predicted_classes.numpy())  # Thêm nhãn dự đoán vào danh sách\n",
    "        all_labels.extend(labels.unsqueeze(0).numpy())  # Thêm nhãn thực tế vào danh sách\n",
    "\n",
    "# Tính toán các chỉ số đánh giá\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')  # Tính precision cho đa lớp\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')  # Tính recall cho đa lớp\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')  # Tính F1-score cho đa lớp\n",
    "confusion = confusion_matrix(all_labels, all_preds)  # Tính confusion matrix\n",
    "\n",
    "# In ra các kết quả đánh giá\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. Thiết lập các siêu tham số\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "# 2. Chuẩn bị dữ liệu MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Chuyển đổi hình ảnh thành tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Chuẩn hóa\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data torch.Size([64, 1, 28, 28])\n",
      "labels tensor([9, 1, 4, 1, 0, 2, 0, 2, 8, 4, 9, 7, 2, 3, 6, 9, 7, 6, 9, 7, 2, 1, 7, 2,\n",
      "        8, 5, 1, 8, 3, 9, 8, 6, 2, 3, 7, 5, 3, 9, 9, 4, 2, 2, 9, 0, 8, 8, 2, 9,\n",
      "        5, 7, 2, 0, 7, 7, 7, 8, 9, 9, 8, 8, 5, 4, 8, 8])\n",
      "data torch.Size([64, 1, 28, 28])\n",
      "labels tensor([6, 4, 5, 7, 0, 7, 8, 8, 3, 1, 0, 7, 0, 7, 1, 6, 9, 3, 0, 0, 7, 9, 9, 0,\n",
      "        1, 1, 7, 7, 8, 2, 8, 1, 0, 6, 8, 9, 8, 0, 9, 6, 4, 8, 9, 8, 8, 3, 5, 7,\n",
      "        6, 5, 2, 2, 9, 6, 4, 6, 9, 7, 1, 5, 8, 9, 9, 1])\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for data, labels in train_loader:\n",
    "    print(\"data\", data.shape)\n",
    "    print(\"labels\", labels)\n",
    "    if i ==2:\n",
    "        break\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming `model` is your neural network\n",
    "torch.save(model.state_dict(), 'model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
